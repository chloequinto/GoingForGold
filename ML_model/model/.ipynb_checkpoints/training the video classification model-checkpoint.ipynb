{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Video Classification\n",
    "\n",
    "**Note:** \n",
    "Just run this notebook alone\n",
    "Setup.ipynb and training videos needs to be changed before running all notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0.mp4_frame0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0.mp4_frame1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_0.mp4_frame2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_0.mp4_frame3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_0.mp4_frame0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_0.mp4_frame1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2_0.mp4_frame10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2_0.mp4_frame11.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2_0.mp4_frame12.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2_0.mp4_frame13.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2_0.mp4_frame14.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2_0.mp4_frame15.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2_0.mp4_frame16.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2_0.mp4_frame17.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2_0.mp4_frame18.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2_0.mp4_frame19.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2_0.mp4_frame2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2_0.mp4_frame20.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2_0.mp4_frame21.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2_0.mp4_frame22.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_0.mp4_frame23.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2_0.mp4_frame24.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2_0.mp4_frame3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2_0.mp4_frame4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2_0.mp4_frame5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2_0.mp4_frame6.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2_0.mp4_frame7.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2_0.mp4_frame8.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2_0.mp4_frame9.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3_1.mp4_frame0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3_1.mp4_frame1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3_1.mp4_frame2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3_1.mp4_frame3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3_1.mp4_frame4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3_1.mp4_frame5.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3_1.mp4_frame6.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_1.mp4_frame7.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image  class\n",
       "0    1_0.mp4_frame0.jpg      0\n",
       "1    1_0.mp4_frame1.jpg      0\n",
       "2    1_0.mp4_frame2.jpg      0\n",
       "3    1_0.mp4_frame3.jpg      0\n",
       "4    2_0.mp4_frame0.jpg      0\n",
       "5    2_0.mp4_frame1.jpg      0\n",
       "6   2_0.mp4_frame10.jpg      0\n",
       "7   2_0.mp4_frame11.jpg      0\n",
       "8   2_0.mp4_frame12.jpg      0\n",
       "9   2_0.mp4_frame13.jpg      0\n",
       "10  2_0.mp4_frame14.jpg      0\n",
       "11  2_0.mp4_frame15.jpg      0\n",
       "12  2_0.mp4_frame16.jpg      0\n",
       "13  2_0.mp4_frame17.jpg      0\n",
       "14  2_0.mp4_frame18.jpg      0\n",
       "15  2_0.mp4_frame19.jpg      0\n",
       "16   2_0.mp4_frame2.jpg      0\n",
       "17  2_0.mp4_frame20.jpg      0\n",
       "18  2_0.mp4_frame21.jpg      0\n",
       "19  2_0.mp4_frame22.jpg      0\n",
       "20  2_0.mp4_frame23.jpg      0\n",
       "21  2_0.mp4_frame24.jpg      0\n",
       "22   2_0.mp4_frame3.jpg      0\n",
       "23   2_0.mp4_frame4.jpg      0\n",
       "24   2_0.mp4_frame5.jpg      0\n",
       "25   2_0.mp4_frame6.jpg      0\n",
       "26   2_0.mp4_frame7.jpg      0\n",
       "27   2_0.mp4_frame8.jpg      0\n",
       "28   2_0.mp4_frame9.jpg      0\n",
       "29   3_1.mp4_frame0.jpg      1\n",
       "30   3_1.mp4_frame1.jpg      1\n",
       "31   3_1.mp4_frame2.jpg      1\n",
       "32   3_1.mp4_frame3.jpg      1\n",
       "33   3_1.mp4_frame4.jpg      1\n",
       "34   3_1.mp4_frame5.jpg      1\n",
       "35   3_1.mp4_frame6.jpg      1\n",
       "36   3_1.mp4_frame7.jpg      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in training frames  \n",
    "train = pd.read_csv('myVids/train_new.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this dataframe showing? \n",
    "\n",
    "This dataframe called \"train\" has two columns: \"image\" and \"class\"\n",
    "- \"image\": contains names of each frame \n",
    "- \"class\": contains corresponding class for each frame\n",
    "\n",
    "##### What does class numbers mean?\n",
    "0 for good serve   \n",
    "1 for bad serve \n",
    "\n",
    "In this case, **video 1 and 3** is a bad serve and **video 2 and 4** are good serves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 61.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37, 224, 224, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image = []\n",
    "\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('train_1/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)\n",
    "    \n",
    "# converting the list to numpy array\n",
    "X = np.array(train_image)\n",
    "\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 37 images each of size 224, 224 and 3. Next we will create a validation set. \n",
    "\n",
    "We need to do **two** things to train our model: \n",
    "- train images\n",
    "- their corresponding model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "26    0\n",
      "27    0\n",
      "28    0\n",
      "29    1\n",
      "30    1\n",
      "31    1\n",
      "32    1\n",
      "33    1\n",
      "34    1\n",
      "35    1\n",
      "36    1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = train[\"class\"]\n",
    "print(train['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot Encoding Classes \n",
    "\n",
    "Since we have 2 classes: 0 and 1 (which are numerical data) we need to convert to categorical\n",
    "\n",
    "[Click me for more info on one hot encoding](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y = to_categorical(y)    # one hot encoding Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 parameters\n",
    "\n",
    "VGG16 takes an input shape of (224 x 224 x 3) \n",
    "\n",
    "Our images are all different sizes so let's reshape them using resize() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for i in range(0,X.shape[0]): \n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess \n",
    "\n",
    "This function preprocess our images so that it fits within the VGG16 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X, mode='tf')      # preprocessing the input dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split ya models \n",
    "Why do we need to split our models? Because right now we only have training images, we need to have a validation set to check the performance of models on unseen images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)    # preparing the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build the model from VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why include_top = False\n",
    "\n",
    "Fully connected layers at the end can only take fixed size inputs which was probably where we were going wrong "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 7, 7, 512), (12, 7, 7, 512))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape into single dimensions by below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(25, 7*7*512)\n",
    "X_valid = X_valid.reshape(12, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize me \n",
    "train = X_train/X_train.max()      \n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to setting up model \n",
    "1. Build model \n",
    "2. Compile model \n",
    "3. Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 25,693,186\n",
      "Trainable params: 25,693,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does model.summary() show us? \n",
    "\n",
    "We have a hidden layer with 1,024 neurons and output layer with 2 neurons(3 classes to predict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 1.4668 - accuracy: 0.2400 - val_loss: 0.4821 - val_accuracy: 0.8333\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6535 - accuracy: 0.7600 - val_loss: 0.7170 - val_accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 1.0260 - accuracy: 0.7600 - val_loss: 0.7952 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 1.1411 - accuracy: 0.7600 - val_loss: 0.7409 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 1.0613 - accuracy: 0.7600 - val_loss: 0.6056 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.8582 - accuracy: 0.7600 - val_loss: 0.4673 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.6232 - accuracy: 0.7600 - val_loss: 0.5274 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5755 - accuracy: 0.7600 - val_loss: 0.8358 - val_accuracy: 0.1667\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.8082 - accuracy: 0.2400 - val_loss: 0.8580 - val_accuracy: 0.1667\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.8267 - accuracy: 0.2400 - val_loss: 0.6131 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.6326 - accuracy: 0.7600 - val_loss: 0.4604 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.5519 - accuracy: 0.7600 - val_loss: 0.4650 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.6184 - accuracy: 0.7600 - val_loss: 0.5043 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.6944 - accuracy: 0.7600 - val_loss: 0.5171 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.7166 - accuracy: 0.7600 - val_loss: 0.4962 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.6801 - accuracy: 0.7600 - val_loss: 0.4611 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.6091 - accuracy: 0.7600 - val_loss: 0.4550 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.5544 - accuracy: 0.7600 - val_loss: 0.5209 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.5715 - accuracy: 0.7600 - val_loss: 0.6136 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.6329 - accuracy: 0.7600 - val_loss: 0.6205 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.6379 - accuracy: 0.7600 - val_loss: 0.5409 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5833 - accuracy: 0.7600 - val_loss: 0.4699 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.5507 - accuracy: 0.7600 - val_loss: 0.4501 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5668 - accuracy: 0.7600 - val_loss: 0.4559 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.5956 - accuracy: 0.7600 - val_loss: 0.4592 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.6049 - accuracy: 0.7600 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.5883 - accuracy: 0.7600 - val_loss: 0.4505 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5615 - accuracy: 0.7600 - val_loss: 0.4692 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5503 - accuracy: 0.7600 - val_loss: 0.5106 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5657 - accuracy: 0.7600 - val_loss: 0.5397 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.5824 - accuracy: 0.7600 - val_loss: 0.5259 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5740 - accuracy: 0.7600 - val_loss: 0.4874 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5549 - accuracy: 0.7600 - val_loss: 0.4592 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5506 - accuracy: 0.7600 - val_loss: 0.4502 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5608 - accuracy: 0.7600 - val_loss: 0.4495 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5690 - accuracy: 0.7600 - val_loss: 0.4494 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5656 - accuracy: 0.7600 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5551 - accuracy: 0.7600 - val_loss: 0.4653 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5495 - accuracy: 0.7600 - val_loss: 0.4872 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5545 - accuracy: 0.7600 - val_loss: 0.5023 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5611 - accuracy: 0.7600 - val_loss: 0.4967 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5584 - accuracy: 0.7600 - val_loss: 0.4773 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5511 - accuracy: 0.7600 - val_loss: 0.4605 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5495 - accuracy: 0.7600 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5536 - accuracy: 0.7600 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5564 - accuracy: 0.7600 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5540 - accuracy: 0.7600 - val_loss: 0.4581 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.5498 - accuracy: 0.7600 - val_loss: 0.4696 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.5491 - accuracy: 0.7600 - val_loss: 0.4816 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5520 - accuracy: 0.7600 - val_loss: 0.4850 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5531 - accuracy: 0.7600 - val_loss: 0.4774 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5506 - accuracy: 0.7600 - val_loss: 0.4658 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5485 - accuracy: 0.7600 - val_loss: 0.4575 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5494 - accuracy: 0.7600 - val_loss: 0.4541 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5510 - accuracy: 0.7600 - val_loss: 0.4545 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5506 - accuracy: 0.7600 - val_loss: 0.4584 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5488 - accuracy: 0.7600 - val_loss: 0.4656 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5481 - accuracy: 0.7600 - val_loss: 0.4731 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5491 - accuracy: 0.7600 - val_loss: 0.4759 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5497 - accuracy: 0.7600 - val_loss: 0.4721 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5488 - accuracy: 0.7600 - val_loss: 0.4650 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5477 - accuracy: 0.7600 - val_loss: 0.4592 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5480 - accuracy: 0.7600 - val_loss: 0.4565 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.5487 - accuracy: 0.7600 - val_loss: 0.4570 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5484 - accuracy: 0.7600 - val_loss: 0.4602 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5476 - accuracy: 0.7600 - val_loss: 0.4653 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5474 - accuracy: 0.7600 - val_loss: 0.4696 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5478 - accuracy: 0.7600 - val_loss: 0.4704 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5479 - accuracy: 0.7600 - val_loss: 0.4672 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5473 - accuracy: 0.7600 - val_loss: 0.4626 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.5470 - accuracy: 0.7600 - val_loss: 0.4592 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5471 - accuracy: 0.7600 - val_loss: 0.4580 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5473 - accuracy: 0.7600 - val_loss: 0.4591 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5470 - accuracy: 0.7600 - val_loss: 0.4621 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5466 - accuracy: 0.7600 - val_loss: 0.4654 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5466 - accuracy: 0.7600 - val_loss: 0.4672 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.5467 - accuracy: 0.7600 - val_loss: 0.4662 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5465 - accuracy: 0.7600 - val_loss: 0.4634 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5463 - accuracy: 0.7600 - val_loss: 0.4606 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.5462 - accuracy: 0.7600 - val_loss: 0.4590 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5462 - accuracy: 0.7600 - val_loss: 0.4593 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5461 - accuracy: 0.7600 - val_loss: 0.4610 - val_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5459 - accuracy: 0.7600 - val_loss: 0.4633 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5458 - accuracy: 0.7600 - val_loss: 0.4648 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5458 - accuracy: 0.7600 - val_loss: 0.4645 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 0.5457 - accuracy: 0.7600 - val_loss: 0.4628 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n"
     ]
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this show us? \n",
    "\n",
    "Accuray of 68%\n",
    "\n",
    "Why so low? Because setup.ipynb needs to be changed because videos are all \"good\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
