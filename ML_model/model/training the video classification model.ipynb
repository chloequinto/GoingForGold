{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Video Classification\n",
    "\n",
    "**Note:** \n",
    "Just run this notebook alone\n",
    "Setup.ipynb and training videos needs to be changed before running all notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0.mp4_frame0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0.mp4_frame1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_0.mp4_frame2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_0.mp4_frame3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_0.mp4_frame0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_0.mp4_frame1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2_0.mp4_frame10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2_0.mp4_frame11.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2_0.mp4_frame12.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2_0.mp4_frame13.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2_0.mp4_frame14.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2_0.mp4_frame15.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2_0.mp4_frame16.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2_0.mp4_frame17.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2_0.mp4_frame18.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2_0.mp4_frame19.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2_0.mp4_frame2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2_0.mp4_frame20.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2_0.mp4_frame21.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2_0.mp4_frame22.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2_0.mp4_frame23.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2_0.mp4_frame24.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2_0.mp4_frame3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2_0.mp4_frame4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2_0.mp4_frame5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2_0.mp4_frame6.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2_0.mp4_frame7.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2_0.mp4_frame8.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2_0.mp4_frame9.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3_1.mp4_frame0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3_1.mp4_frame1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3_1.mp4_frame2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3_1.mp4_frame3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3_1.mp4_frame4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3_1.mp4_frame5.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3_1.mp4_frame6.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3_1.mp4_frame7.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image  class\n",
       "0    1_0.mp4_frame0.jpg      0\n",
       "1    1_0.mp4_frame1.jpg      0\n",
       "2    1_0.mp4_frame2.jpg      0\n",
       "3    1_0.mp4_frame3.jpg      0\n",
       "4    2_0.mp4_frame0.jpg      0\n",
       "5    2_0.mp4_frame1.jpg      0\n",
       "6   2_0.mp4_frame10.jpg      0\n",
       "7   2_0.mp4_frame11.jpg      0\n",
       "8   2_0.mp4_frame12.jpg      0\n",
       "9   2_0.mp4_frame13.jpg      0\n",
       "10  2_0.mp4_frame14.jpg      0\n",
       "11  2_0.mp4_frame15.jpg      0\n",
       "12  2_0.mp4_frame16.jpg      0\n",
       "13  2_0.mp4_frame17.jpg      0\n",
       "14  2_0.mp4_frame18.jpg      0\n",
       "15  2_0.mp4_frame19.jpg      0\n",
       "16   2_0.mp4_frame2.jpg      0\n",
       "17  2_0.mp4_frame20.jpg      0\n",
       "18  2_0.mp4_frame21.jpg      0\n",
       "19  2_0.mp4_frame22.jpg      0\n",
       "20  2_0.mp4_frame23.jpg      0\n",
       "21  2_0.mp4_frame24.jpg      0\n",
       "22   2_0.mp4_frame3.jpg      0\n",
       "23   2_0.mp4_frame4.jpg      0\n",
       "24   2_0.mp4_frame5.jpg      0\n",
       "25   2_0.mp4_frame6.jpg      0\n",
       "26   2_0.mp4_frame7.jpg      0\n",
       "27   2_0.mp4_frame8.jpg      0\n",
       "28   2_0.mp4_frame9.jpg      0\n",
       "29   3_1.mp4_frame0.jpg      1\n",
       "30   3_1.mp4_frame1.jpg      1\n",
       "31   3_1.mp4_frame2.jpg      1\n",
       "32   3_1.mp4_frame3.jpg      1\n",
       "33   3_1.mp4_frame4.jpg      1\n",
       "34   3_1.mp4_frame5.jpg      1\n",
       "35   3_1.mp4_frame6.jpg      1\n",
       "36   3_1.mp4_frame7.jpg      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in training frames  \n",
    "train = pd.read_csv('myVids/train_new.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this dataframe showing? \n",
    "\n",
    "This dataframe called \"train\" has two columns: \"image\" and \"class\"\n",
    "- \"image\": contains names of each frame \n",
    "- \"class\": contains corresponding class for each frame\n",
    "\n",
    "##### What does class numbers mean?\n",
    "0 for good serve   \n",
    "1 for bad serve \n",
    "\n",
    "In this case, **video 1 and 3** is a bad serve and **video 2 and 4** are good serves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 66.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37, 224, 224, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image = []\n",
    "\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('train_1/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)\n",
    "    \n",
    "# converting the list to numpy array\n",
    "X = np.array(train_image)\n",
    "\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 37 images each of size 224, 224 and 3. Next we will create a validation set. \n",
    "\n",
    "We need to do **two** things to train our model: \n",
    "- train images\n",
    "- their corresponding model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "26    0\n",
      "27    0\n",
      "28    0\n",
      "29    1\n",
      "30    1\n",
      "31    1\n",
      "32    1\n",
      "33    1\n",
      "34    1\n",
      "35    1\n",
      "36    1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = train[\"class\"]\n",
    "print(train['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot Encoding Classes \n",
    "\n",
    "Since we have 2 classes: 0 and 1 (which are numerical data) we need to convert to categorical\n",
    "\n",
    "[Click me for more info on one hot encoding](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y = to_categorical(y)    # one hot encoding Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 parameters\n",
    "\n",
    "VGG16 takes an input shape of (224 x 224 x 3) \n",
    "\n",
    "Our images are all different sizes so let's reshape them using resize() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for i in range(0,X.shape[0]): \n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess \n",
    "\n",
    "This function preprocess our images so that it fits within the VGG16 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X, mode='tf')      # preprocessing the input dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split ya models \n",
    "Why do we need to split our models? Because right now we only have training images, we need to have a validation set to check the performance of models on unseen images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)    # preparing the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build the model from VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why include_top = False\n",
    "\n",
    "Fully connected layers at the end can only take fixed size inputs which was probably where we were going wrong "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 7, 7, 512), (12, 7, 7, 512))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape into single dimensions by below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(25, 7*7*512)\n",
    "X_valid = X_valid.reshape(12, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize me \n",
    "train = X_train/X_train.max()      \n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to setting up model \n",
    "1. Build model \n",
    "2. Compile model \n",
    "3. Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid', input_shape=(7*7*512,))) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 25,693,186\n",
      "Trainable params: 25,693,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does model.summary() show us? \n",
    "\n",
    "We have a hidden layer with 1,024 neurons and output layer with 2 neurons(3 classes to predict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.6485 - accuracy: 0.7600 - val_loss: 0.7200 - val_accuracy: 0.8333\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 1.0305 - accuracy: 0.7600 - val_loss: 0.6718 - val_accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.9587 - accuracy: 0.7600 - val_loss: 0.4732 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.6360 - accuracy: 0.7600 - val_loss: 0.6603 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6678 - accuracy: 0.7600 - val_loss: 0.8213 - val_accuracy: 0.1667\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.7962 - accuracy: 0.2400 - val_loss: 0.5385 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5820 - accuracy: 0.7600 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5835 - accuracy: 0.7600 - val_loss: 0.4955 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.6789 - accuracy: 0.7600 - val_loss: 0.5048 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.6954 - accuracy: 0.7600 - val_loss: 0.4701 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.6298 - accuracy: 0.7600 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5565 - accuracy: 0.7600 - val_loss: 0.5369 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5809 - accuracy: 0.7600 - val_loss: 0.6300 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.6449 - accuracy: 0.7600 - val_loss: 0.5732 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.6043 - accuracy: 0.7600 - val_loss: 0.4762 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5517 - accuracy: 0.7600 - val_loss: 0.4500 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5700 - accuracy: 0.7600 - val_loss: 0.4587 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.6037 - accuracy: 0.7600 - val_loss: 0.4584 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6029 - accuracy: 0.7600 - val_loss: 0.4500 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5714 - accuracy: 0.7600 - val_loss: 0.4647 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5500 - accuracy: 0.7600 - val_loss: 0.5169 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5690 - accuracy: 0.7600 - val_loss: 0.5484 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5878 - accuracy: 0.7600 - val_loss: 0.5151 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5679 - accuracy: 0.7600 - val_loss: 0.4680 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5498 - accuracy: 0.7600 - val_loss: 0.4503 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5597 - accuracy: 0.7600 - val_loss: 0.4497 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5729 - accuracy: 0.7600 - val_loss: 0.4493 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5684 - accuracy: 0.7600 - val_loss: 0.4533 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5535 - accuracy: 0.7600 - val_loss: 0.4751 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5506 - accuracy: 0.7600 - val_loss: 0.5044 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5620 - accuracy: 0.7600 - val_loss: 0.5071 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5633 - accuracy: 0.7600 - val_loss: 0.4814 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5522 - accuracy: 0.7600 - val_loss: 0.4585 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5498 - accuracy: 0.7600 - val_loss: 0.4504 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5568 - accuracy: 0.7600 - val_loss: 0.4496 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5588 - accuracy: 0.7600 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5526 - accuracy: 0.7600 - val_loss: 0.4656 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5486 - accuracy: 0.7600 - val_loss: 0.4842 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5528 - accuracy: 0.7600 - val_loss: 0.4908 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5553 - accuracy: 0.7600 - val_loss: 0.4783 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5507 - accuracy: 0.7600 - val_loss: 0.4618 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5483 - accuracy: 0.7600 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5513 - accuracy: 0.7600 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5526 - accuracy: 0.7600 - val_loss: 0.4554 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5497 - accuracy: 0.7600 - val_loss: 0.4651 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5478 - accuracy: 0.7600 - val_loss: 0.4769 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5499 - accuracy: 0.7600 - val_loss: 0.4797 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5506 - accuracy: 0.7600 - val_loss: 0.4710 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5483 - accuracy: 0.7600 - val_loss: 0.4603 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5476 - accuracy: 0.7600 - val_loss: 0.4548 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5491 - accuracy: 0.7600 - val_loss: 0.4545 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5491 - accuracy: 0.7600 - val_loss: 0.4590 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5474 - accuracy: 0.7600 - val_loss: 0.4671 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5472 - accuracy: 0.7600 - val_loss: 0.4733 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5483 - accuracy: 0.7600 - val_loss: 0.4716 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5478 - accuracy: 0.7600 - val_loss: 0.4643 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5467 - accuracy: 0.7600 - val_loss: 0.4580 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5470 - accuracy: 0.7600 - val_loss: 0.4558 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5475 - accuracy: 0.7600 - val_loss: 0.4577 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5468 - accuracy: 0.7600 - val_loss: 0.4629 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5462 - accuracy: 0.7600 - val_loss: 0.4682 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5466 - accuracy: 0.7600 - val_loss: 0.4690 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5467 - accuracy: 0.7600 - val_loss: 0.4647 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5460 - accuracy: 0.7600 - val_loss: 0.4596 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5459 - accuracy: 0.7600 - val_loss: 0.4571 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5462 - accuracy: 0.7600 - val_loss: 0.4579 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5459 - accuracy: 0.7600 - val_loss: 0.4614 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5455 - accuracy: 0.7600 - val_loss: 0.4653 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5456 - accuracy: 0.7600 - val_loss: 0.4662 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5456 - accuracy: 0.7600 - val_loss: 0.4635 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5452 - accuracy: 0.7600 - val_loss: 0.4598 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5450 - accuracy: 0.7600 - val_loss: 0.4577 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5451 - accuracy: 0.7600 - val_loss: 0.4583 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5449 - accuracy: 0.7600 - val_loss: 0.4609 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5446 - accuracy: 0.7600 - val_loss: 0.4636 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5446 - accuracy: 0.7600 - val_loss: 0.4640 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5446 - accuracy: 0.7600 - val_loss: 0.4618 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5443 - accuracy: 0.7600 - val_loss: 0.4592 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5442 - accuracy: 0.7600 - val_loss: 0.4579 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5442 - accuracy: 0.7600 - val_loss: 0.4587 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5440 - accuracy: 0.7600 - val_loss: 0.4607 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5438 - accuracy: 0.7600 - val_loss: 0.4623 - val_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5437 - accuracy: 0.7600 - val_loss: 0.4620 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5436 - accuracy: 0.7600 - val_loss: 0.4602 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5434 - accuracy: 0.7600 - val_loss: 0.4584 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5433 - accuracy: 0.7600 - val_loss: 0.4580 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5432 - accuracy: 0.7600 - val_loss: 0.4589 - val_accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5430 - accuracy: 0.7600 - val_loss: 0.4604 - val_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5429 - accuracy: 0.7600 - val_loss: 0.4611 - val_accuracy: 0.8333\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5428 - accuracy: 0.7600 - val_loss: 0.4602 - val_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5427 - accuracy: 0.7600 - val_loss: 0.4587 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5425 - accuracy: 0.7600 - val_loss: 0.4578 - val_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5424 - accuracy: 0.7600 - val_loss: 0.4580 - val_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5423 - accuracy: 0.7600 - val_loss: 0.4590 - val_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5421 - accuracy: 0.7600 - val_loss: 0.4598 - val_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5420 - accuracy: 0.7600 - val_loss: 0.4596 - val_accuracy: 0.8333\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5419 - accuracy: 0.7600 - val_loss: 0.4586 - val_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5417 - accuracy: 0.7600 - val_loss: 0.4576 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.5416 - accuracy: 0.7600 - val_loss: 0.4574 - val_accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5415 - accuracy: 0.7600 - val_loss: 0.4579 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1dd666cf278>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[mcp_save], batch_size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this show us? \n",
    "\n",
    "Accuray of 68%\n",
    "\n",
    "Why so low? Because setup.ipynb needs to be changed because videos are all \"good\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
