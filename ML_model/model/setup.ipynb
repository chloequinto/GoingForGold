{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Script\n",
    "To be run after new videos are added\n",
    "\n",
    "Based on the article [Guide to Build Video Classification Model](https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\stevensuser\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.1.1.26)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\stevensuser\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from opencv-python) (1.17.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os, os.path\n",
    "import cv2  # for caputring videos\n",
    "import math # for mathematical operations\n",
    "import matplotlib.pyplot as plt # for plotting the images\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image # for preprocessing the images\n",
    "import numpy as np # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from numpy import genfromtxt\n",
    "from skimage.transform import resize # for resizing images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the name of videos in a dataframe\n",
    "First bit opens the file, reads the file, and splits them by \"enter\"\n",
    "\n",
    "Second bit creates a dataframe and stores the above extracted video names under \"train['video_name']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the .txt file which have names of training videos\n",
    "# f = open(\"trainlist_tennis.txt\", \"r\")\n",
    "# temp = f.read()\n",
    "# videos = temp.split(\"\\n\")\n",
    "# print(videos)\n",
    "\n",
    "# creating a dataframe having video names\n",
    "# train = pd.DataFrame()\n",
    "# train['video_name'] = videos\n",
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Turn the csv files into dataframes\n",
    " Things to prep:\n",
    " 1. Create folder with the name \"training_csv\"\n",
    " 2. Create files with proper naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path=\"dataPoints/\"\n",
    "\n",
    "convertFile = pd.DataFrame()\n",
    "\n",
    "for filename in glob(os.path.join(path, '*.csv')):    \n",
    "    file = filename.split(\"/\")[1]\n",
    "    convertFile = pd.read_csv(path + file, header=None)\n",
    "    \n",
    "#     locals()['dict{}'.format(\"_\" + file.split(\".csv\")[0])] = {}\n",
    "    D = {}\n",
    "        \n",
    "    size = len(convertFile[0]) // 12\n",
    "    \n",
    "    for i in range((len(convertFile) + 12 - 1) // 12):\n",
    "        data = convertFile.to_numpy()[i:i+12]\n",
    "        data = np.delete(data, 0, 1)\n",
    "        data = np.reshape(data, (24, 1))\n",
    "#         locals()['dict{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)] = data\n",
    "        D = data\n",
    "#     print(D)\n",
    "    \n",
    "#     for i in locals()['dict{}'.format(\"_\" + file.split(\".csv\")[0])]:\n",
    "#         combine = locals()['dict{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)]\n",
    "        \n",
    "#         if int(i) < len(locals()['dict{}'.format(\"_\" + file.split(\".csv\")[0])]):\n",
    "#             j = int(i)+1\n",
    "#             combineTwo = locals()['dict{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(j)]\n",
    "\n",
    "    for i in D:\n",
    "        combine = D\n",
    "        if int(i) < len(D):\n",
    "            j = int(i)+1\n",
    "            combineTwo = D.format(j)\n",
    "\n",
    "# print(dict_training_file_1_b)\n",
    "# print(dict_training_file_1_b[\"0\"])\n",
    "# print(dict_training_file_1_b[\"0\"].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     for i in range(0, size-1):\n",
    "#         data = np.append(data, [convertFile.loc[i, :].to_numpy()], axis=0)    \n",
    "        \n",
    "    \n",
    "    \n",
    "#     size = math.floor(len(convertFile))//12\n",
    "    \n",
    "#     for i in range(1, size):\n",
    "#         trainFrame[i] = convertFile[i]\n",
    "    \n",
    "    \n",
    "#     print(trainFrame[0])\n",
    "    \n",
    "#     splitArray = np.array_split(convertFile, size)\n",
    "    \n",
    "#     print(splitArray[0][0])\n",
    "    \n",
    "    \n",
    "#     print(convertFile)\n",
    "#     np.array_split(convertFile, size)\n",
    "    \n",
    "#     for i in range(0, size):\n",
    "#         trainFrame[i] = convertFile[i]\n",
    "    \n",
    "#     print(trainFrame[0])\n",
    "    \n",
    "#     print(np.array_split(convertFile, size))\n",
    "#         print(np.array_split(trainFrame_i, size))\n",
    "    \n",
    "    \n",
    "#     for j in range (len(trainFrame_i)):\n",
    "#         trainFrame_i[j].reshape((14,1))\n",
    "    \n",
    "#     for j in range (len(trainFrame_i)):\n",
    "#         trainFrame_j[j] = trainFrame_i[j]\n",
    "#         trainFrame_j[j].append(trainFrame_i[j+1])\n",
    "#         trainFrame_j[j].append(trainFrame_i[j+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a similar dataframe for the test videos\n",
    "Does the same thing as above but for the test video names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # open the .txt file which have names of test videos\n",
    "# f = open(\"testlist_tennis.txt\", \"r\")\n",
    "# temp = f.read()\n",
    "# videos = temp.split('\\n')\n",
    "\n",
    "# # creating a dataframe having video names\n",
    "# test = pd.DataFrame()\n",
    "# test['video_name'] = videos\n",
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the same for test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(dir) #dir of where we will place folder, to be replaced with actual name\n",
    "\n",
    "for i in range (len(files)):\n",
    "    testFrame_i = pd.read_csv('training_file_', i, '.csv')\n",
    "    testFrame_i = testFrame.to_numpy()\n",
    "    \n",
    "    size = math.floor((len(testFrame_i)/12 * (10 ** 0))/ (10 ** 0))\n",
    "    testFrame_i.split(testFrame_i, size)\n",
    "    \n",
    "    for j in range (len(testFrame_i)):\n",
    "        testFrame_i[j].reshape((14,1))\n",
    "    \n",
    "    for j in range (len(trainFrame_i)):\n",
    "        testFrame_j[j] = testFrame_i[j]\n",
    "        testFrame_j[j].append(testFrame_i[j+1])\n",
    "        testFrame_j[j].append(testFrame_i[j+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the tags\n",
    "For both training and test sets: grabs the tag (0 or 1/good or bad serve) from the text file and stores in the respective dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating tags for training videos\n",
    "# train_video_tag = []\n",
    "# for i in range(train.shape[0]):\n",
    "#     train_video_tag.append(train['video_name'][i].split('_')[1].split('.')[0])\n",
    "    \n",
    "# train['tag'] = train_video_tag\n",
    "\n",
    "# # creating tags for test videos\n",
    "# test_video_tag = []\n",
    "# for i in range(test.shape[0]):\n",
    "#     test_video_tag.append(test['video_name'][i].split('_')[1].split('.')[0])\n",
    "    \n",
    "# test['tag'] = test_video_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is what the test dataframe looks like \n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what the train dataframe looks like \n",
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the tags\n",
    "This is assuming this is first column of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_tag = []\n",
    "for i in range(len(files)):\n",
    "    train_video_tag.append(trainFrame_i[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame Extraction and Storing\n",
    "All frames are put in a folder named train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # open the .txt file which have names of training videos\n",
    "# f = open(\"trainlist_tennis.txt\", \"r\")\n",
    "# temp = f.read()\n",
    "# videos = temp.split(\"\\n\")\n",
    "\n",
    "# train = pd.DataFrame()\n",
    "# train['video_name'] = videos\n",
    "\n",
    "# # storing the frames from training videos\n",
    "# for i in tqdm(range(len(file))):\n",
    "#     count = 0\n",
    "#     videoFile = train['video_name'][i]\n",
    "#     cap = cv2.VideoCapture('myVids/'+videoFile)   # capturing the video from the given path\n",
    "#     frameRate = cap.get(5) #frame rate\n",
    "#     x=1\n",
    "#     while(cap.isOpened()):\n",
    "#         frameId = cap.get(1) #current frame number\n",
    "#         ret, frame = cap.read()\n",
    "#         if (ret != True):\n",
    "#             break\n",
    "#         if (frameId % math.floor(frameRate) == 0):\n",
    "#             # storing the frames in a new folder named train_1\n",
    "#             print(\"this is the split\")\n",
    "#             print(videoFile.split(\" \")[0]) #since my videos aren't in separate folder, no need to split based on (\"/\")\n",
    "            \n",
    "#             #need to make sure that the train_1 has been created\n",
    "#             filename ='train_1/' + videoFile.split(' ')[0] +\"_frame%d.jpg\" % count;count+=1\n",
    "#             cv2.imwrite(filename, frame)\n",
    "#     cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .csv file\n",
    "Get the names of all the frames with their corresponding tag and put the info into a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# #getting the names of all the images\n",
    "# images = glob(\"train_1/*.jpg\")\n",
    "# train_image = []\n",
    "# train_class = []\n",
    "\n",
    "# for i in tqdm(range(len(images))):\n",
    "#     # creating the image name\n",
    "#     train_image.append(images[i].split(\"\\\\\")[1])  #uncomment this for windows\n",
    "#     #train_image.append(images[i].split(\"/\")[1])  #uncomment this for mac\n",
    "#     # creating the class of image\n",
    "#     train_class.append(images[i].split(\"\\\\\")[1].split(\".\")[0].split(\"_\")[1]) #uncomment this for windows\n",
    "#     #train_class.append(images[i].split(\"/\")[1].split(\".\")[0].split(\"_\")[1]) #uncomment this for mac\n",
    "    \n",
    "# # storing the images and their class in a dataframe\n",
    "# train_data = pd.DataFrame()\n",
    "# train_data['image'] = train_image\n",
    "# train_data['class'] = train_class\n",
    "\n",
    "# # converting the dataframe into csv file \n",
    "# train_data.to_csv('myVids/train_new.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
